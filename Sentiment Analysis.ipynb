{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32947,
     "status": "ok",
     "timestamp": 1714727108573,
     "user": {
      "displayName": "Roha Kabir",
      "userId": "11189408052881390280"
     },
     "user_tz": -300
    },
    "id": "091Jrvmhd0KE",
    "outputId": "8f4874d2-3799-443e-8d8c-603b3025cdf9"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Mount Google Drive\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 904,
     "status": "ok",
     "timestamp": 1714727141365,
     "user": {
      "displayName": "Roha Kabir",
      "userId": "11189408052881390280"
     },
     "user_tz": -300
    },
    "id": "KWHmgF41s0qB"
   },
   "outputs": [],
   "source": [
    "# Path to the file on Google Drive\n",
    "file_path = 'Philips_Employee_Reviews_from_AmbitionBox.csv'\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Now you can continue with the rest of your code using the 'data' DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 356,
     "status": "ok",
     "timestamp": 1714727320593,
     "user": {
      "displayName": "Roha Kabir",
      "userId": "11189408052881390280"
     },
     "user_tz": -300
    },
    "id": "Gacnpgl6tBtw",
    "outputId": "c1016214-21eb-4c4d-dfe7-2f0e5f40d10c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title                Place  \\\n",
      "0                           Software Developer Cloud              Chennai   \n",
      "1                                       Team Manager              Chennai   \n",
      "2  Engineering Manager Engineering Head Mechanica...    Pune, Maharashtra   \n",
      "3                                  Marketing Manager  Mumbai, Maharashtra   \n",
      "4                                Product Costing BPE              Chennai   \n",
      "\n",
      "    Job_type                       Department        Date  Overall_rating  \\\n",
      "0  Full Time  Software Development Department  4 Sep 2023             1.0   \n",
      "1  Full Time    Retail & B2C Sales Department  2 Sep 2023             3.0   \n",
      "2  Full Time        Connected care Department  0 Sep 2023             3.0   \n",
      "3  Full Time             Marketing Department  7 Sep 2023             1.0   \n",
      "4  Full Time            Operations Department  3 Sep 2023             5.0   \n",
      "\n",
      "   work_life_balance  skill_development  salary_and_benefits  job_security  \\\n",
      "0                1.0                1.0                  3.0           1.0   \n",
      "1                3.0                2.0                  4.0           2.0   \n",
      "2                4.0                4.0                  4.0           3.0   \n",
      "3                2.0                1.0                  3.0           3.0   \n",
      "4                5.0                5.0                  5.0           5.0   \n",
      "\n",
      "   career_growth  work_satisfaction  \\\n",
      "0            1.0                2.0   \n",
      "1            3.0                2.0   \n",
      "2            1.0                1.0   \n",
      "3            1.0                2.0   \n",
      "4            4.0                5.0   \n",
      "\n",
      "                                               Likes  \\\n",
      "0  company culture terrible please dont join wast...   \n",
      "1                         employee benefits policies   \n",
      "2                                  work life balance   \n",
      "3           salary decent work life balance benefits   \n",
      "4  get chance explore different domain big financ...   \n",
      "\n",
      "                                            Dislikes  \n",
      "0  process hectic work load one individual mapped...  \n",
      "1  employee policies good middle level management...  \n",
      "2  growth opportunity work quality per experience...  \n",
      "3  almost startup culture nothing organised struc...  \n",
      "4  dont like people moving process even many year...  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1319 entries, 0 to 1318\n",
      "Data columns (total 14 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Title                1245 non-null   object \n",
      " 1   Place                1175 non-null   object \n",
      " 2   Job_type             519 non-null    object \n",
      " 3   Department           976 non-null    object \n",
      " 4   Date                 1245 non-null   object \n",
      " 5   Overall_rating       1239 non-null   float64\n",
      " 6   work_life_balance    1317 non-null   float64\n",
      " 7   skill_development    1317 non-null   float64\n",
      " 8   salary_and_benefits  1313 non-null   float64\n",
      " 9   job_security         1313 non-null   float64\n",
      " 10  career_growth        1312 non-null   float64\n",
      " 11  work_satisfaction    1309 non-null   float64\n",
      " 12  Likes                1139 non-null   object \n",
      " 13  Dislikes             1085 non-null   object \n",
      "dtypes: float64(7), object(7)\n",
      "memory usage: 144.4+ KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rohak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Preprocess the text data\n",
    "# Remove punctuation, convert text to lowercase, and remove stopwords\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Check if text is a string\n",
    "    if isinstance(text, str):\n",
    "        # Remove punctuation\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        # Convert text to lowercase\n",
    "        text = text.lower()\n",
    "        # Remove stopwords\n",
    "        text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "    return text\n",
    "\n",
    "data['Likes'] = data['Likes'].apply(preprocess_text)\n",
    "data['Dislikes'] = data['Dislikes'].apply(preprocess_text)\n",
    "\n",
    "# Explore the dataset\n",
    "print(data.head())\n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "executionInfo": {
     "elapsed": 5458,
     "status": "ok",
     "timestamp": 1714727506563,
     "user": {
      "displayName": "Roha Kabir",
      "userId": "11189408052881390280"
     },
     "user_tz": -300
    },
    "id": "633imUn0twYW",
    "outputId": "86b64a6e-f03d-4ac2-9b1b-fd54d9f4ba35"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwordcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WordCloud\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Generate word clouds for Likes and Dislikes\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Generate word clouds for Likes and Dislikes\n",
    "likes_text = ' '.join(data['Likes'].apply(lambda x: str(x)))\n",
    "dislikes_text = ' '.join(data['Dislikes'].apply(lambda x: str(x)))\n",
    "\n",
    "\n",
    "likes_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(likes_text)\n",
    "dislikes_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(dislikes_text)\n",
    "\n",
    "# Visualize word clouds\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(likes_wordcloud, interpolation='bilinear')\n",
    "plt.title('Likes Word Cloud')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(dislikes_wordcloud, interpolation='bilinear')\n",
    "plt.title('Dislikes Word Cloud')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 651,
     "status": "ok",
     "timestamp": 1714729012765,
     "user": {
      "displayName": "Roha Kabir",
      "userId": "11189408052881390280"
     },
     "user_tz": -300
    },
    "id": "Qzk5t4-NxRQA",
    "outputId": "601c6625-233e-45e7-df79-74a9c5213d8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4976958525345622\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.47      0.31      0.38        54\n",
      "     neutral       0.43      0.41      0.42        64\n",
      "    positive       0.54      0.66      0.59        99\n",
      "\n",
      "    accuracy                           0.50       217\n",
      "   macro avg       0.48      0.46      0.46       217\n",
      "weighted avg       0.49      0.50      0.49       217\n",
      "\n",
      "Trained model and CountVectorizer instance saved successfully to: model\\sentiment_analysis_model_v1.pkl and model\\count_vectorizer.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rohak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Philips_Employee_Reviews_from_AmbitionBox.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Preprocess the text data\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Check if text is a string\n",
    "    if isinstance(text, str):\n",
    "        # Remove punctuation\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        # Convert text to lowercase\n",
    "        text = text.lower()\n",
    "        # Remove stopwords\n",
    "        text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "data['Likes'] = data['Likes'].apply(preprocess_text)\n",
    "data['Dislikes'] = data['Dislikes'].apply(preprocess_text)\n",
    "\n",
    "# Combine Likes and Dislikes into a single text column\n",
    "data['Text'] = data['Likes'] + ' ' + data['Dislikes']\n",
    "\n",
    "# Drop rows with missing values in both 'Text' and 'Overall_rating' columns\n",
    "data.dropna(subset=['Text', 'Overall_rating'], inplace=True)\n",
    "\n",
    "# Define thresholds for sentiment categories\n",
    "positive_threshold = 5\n",
    "negative_threshold = 3\n",
    "\n",
    "# Map ratings to sentiment categories\n",
    "data['Sentiment'] = data['Overall_rating'].apply(lambda x: 'positive' if x >= positive_threshold else ('negative' if x <= negative_threshold else 'neutral'))\n",
    "\n",
    "# Define features and target\n",
    "X = data['Text']\n",
    "y = data['Sentiment']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the text data using Bag-of-Words\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_vect, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_vect)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Define the directory path for the model folder\n",
    "model_dir = 'model'\n",
    "\n",
    "# Create the model directory if it doesn't exist\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# Define the file paths for saving the trained model and CountVectorizer instance\n",
    "model_file_path = os.path.join(model_dir, 'sentiment_analysis_model_v1.pkl')\n",
    "vectorizer_file_path = os.path.join(model_dir, 'count_vectorizer.pkl')\n",
    "\n",
    "# Save the trained model and CountVectorizer instance to the file paths\n",
    "joblib.dump(model, model_file_path)\n",
    "joblib.dump(vectorizer, vectorizer_file_path)\n",
    "\n",
    "print(\"Trained model and CountVectorizer instance saved successfully to:\", model_file_path, \"and\", vectorizer_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1422,
     "status": "ok",
     "timestamp": 1714731377843,
     "user": {
      "displayName": "Roha Kabir",
      "userId": "11189408052881390280"
     },
     "user_tz": -300
    },
    "id": "GbHDB3We9EHn",
    "outputId": "9a1ed661-f120-4300-f6cf-527c8d383531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7419354838709677\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.29      0.18      0.22        22\n",
      "     neutral       0.43      0.09      0.15        32\n",
      "    positive       0.79      0.94      0.86       163\n",
      "\n",
      "    accuracy                           0.74       217\n",
      "   macro avg       0.50      0.41      0.41       217\n",
      "weighted avg       0.68      0.74      0.69       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# # Combine Likes and Dislikes into a single text column\n",
    "# data['Text'] = data['Likes'] + ' ' + data['Dislikes']\n",
    "\n",
    "# # Drop rows with missing values in both 'Text' and 'Overall_rating' columns\n",
    "# data.dropna(subset=['Text', 'Overall_rating'], inplace=True)\n",
    "\n",
    "# # Define thresholds for sentiment categories\n",
    "# positive_threshold = 6\n",
    "# negative_threshold = 2\n",
    "\n",
    "# # Map ratings to sentiment categories\n",
    "# data['Sentiment'] = data['Overall_rating'].apply(lambda x: 'positive' if x >= positive_threshold else ('negative' if x <= negative_threshold else 'neutral'))\n",
    "\n",
    "# # Define features and target\n",
    "# X = data['Text']\n",
    "# y = data['Sentiment']\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Vectorize the text data using Bag-of-Words\n",
    "# vectorizer = CountVectorizer()\n",
    "# X_train_vect = vectorizer.fit_transform(X_train)\n",
    "# X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "# # Initialize and train the Logistic Regression model\n",
    "# model = LogisticRegression(max_iter=1000)\n",
    "# model.fit(X_train_vect, y_train)\n",
    "\n",
    "# # Predict on the test set\n",
    "# y_pred = model.predict(X_test_vect)\n",
    "\n",
    "# # Evaluate the model\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 412,
     "status": "ok",
     "timestamp": 1714731450559,
     "user": {
      "displayName": "Roha Kabir",
      "userId": "11189408052881390280"
     },
     "user_tz": -300
    },
    "id": "m_1uuSLW9V_L",
    "outputId": "0f634232-36fc-4894-9d45-fa2cb81b2c2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already trained and saved the model\n",
    "\n",
    "# New text input\n",
    "new_text = \"wow i like it\"\n",
    "\n",
    "# Combine likes and dislikes if needed\n",
    "# new_text_combined = preprocess_text(new_text)\n",
    "\n",
    "# Vectorize the new text input\n",
    "new_text_vect = vectorizer.transform([new_text])\n",
    "\n",
    "# Predict the sentiment category\n",
    "predicted_sentiment = model.predict(new_text_vect)[0]\n",
    "\n",
    "print(\"Predicted Sentiment:\", predicted_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 632,
     "status": "ok",
     "timestamp": 1714731539716,
     "user": {
      "displayName": "Roha Kabir",
      "userId": "11189408052881390280"
     },
     "user_tz": -300
    },
    "id": "EJoD_nuN9hCl",
    "outputId": "1226a845-0a34-453e-eb5d-cf8728cd7dcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model saved successfully to: model\\sentiment_analysis_model_v1.pkl\n"
     ]
    }
   ],
   "source": [
    "# import joblib\n",
    "# import os\n",
    "\n",
    "# # Define the directory path for the model folder\n",
    "# model_dir = 'model'\n",
    "\n",
    "# # Create the model directory if it doesn't exist\n",
    "# if not os.path.exists(model_dir):\n",
    "#     os.makedirs(model_dir)\n",
    "\n",
    "# # Define the file path for saving the trained model\n",
    "# model_file_path = os.path.join(model_dir, 'sentiment_analysis_model_v1.pkl')\n",
    "\n",
    "# # Save the trained model to the file path\n",
    "# joblib.dump(model, model_file_path)\n",
    "\n",
    "# print(\"Trained model saved successfully to:\", model_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 370,
     "status": "ok",
     "timestamp": 1714734050075,
     "user": {
      "displayName": "Roha Kabir",
      "userId": "11189408052881390280"
     },
     "user_tz": -300
    },
    "id": "hJCoHDru72Ga"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define aspects\n",
    "aspects = ['work_life_balance', 'salary_and_benefits']\n",
    "\n",
    "# Preprocess the text data\n",
    "# Assuming the data is already preprocessed and contains 'Likes' and 'Dislikes' columns\n",
    "data.dropna(subset=['Likes', 'Dislikes', 'work_life_balance', 'salary_and_benefits'], inplace=True)\n",
    "\n",
    "# Combine Likes and Dislikes into a single text column for each aspect\n",
    "data['work_life_balance_text'] = data['Likes'] + ' ' + data['Dislikes']\n",
    "data['salary_and_benefits_text'] = data['Likes'] + ' ' + data['Dislikes']\n",
    "\n",
    "# Define features and target for each aspect\n",
    "X_work_life_balance = data['work_life_balance_text']\n",
    "X_salary_and_benefits = data['salary_and_benefits_text']\n",
    "y_work_life_balance = data['work_life_balance']\n",
    "y_salary_and_benefits = data['salary_and_benefits']\n",
    "\n",
    "# Split the data into training and testing sets for each aspect\n",
    "X_train_wlb, X_test_wlb, y_train_wlb, y_test_wlb = train_test_split(X_work_life_balance, y_work_life_balance, test_size=0.2, random_state=42)\n",
    "X_train_sal, X_test_sal, y_train_sal, y_test_sal = train_test_split(X_salary_and_benefits, y_salary_and_benefits, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "executionInfo": {
     "elapsed": 1120,
     "status": "ok",
     "timestamp": 1714734053902,
     "user": {
      "displayName": "Roha Kabir",
      "userId": "11189408052881390280"
     },
     "user_tz": -300
    },
    "id": "nj674Q8OD-cL",
    "outputId": "c2081b68-2501-448f-a097-3b77f4d7ab91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize the text data using TF-IDF for each aspect\n",
    "vectorizer_wlb = TfidfVectorizer()\n",
    "X_train_vect_wlb = vectorizer_wlb.fit_transform(X_train_wlb)\n",
    "X_test_vect_wlb = vectorizer_wlb.transform(X_test_wlb)\n",
    "\n",
    "vectorizer_sal = TfidfVectorizer()\n",
    "X_train_vect_sal = vectorizer_sal.fit_transform(X_train_sal)\n",
    "X_test_vect_sal = vectorizer_sal.transform(X_test_sal)\n",
    "\n",
    "# Initialize and train Logistic Regression models for each aspect\n",
    "model_wlb = LogisticRegression(max_iter=1000)\n",
    "model_wlb.fit(X_train_vect_wlb, y_train_wlb)\n",
    "\n",
    "model_sal = LogisticRegression(max_iter=1000)\n",
    "model_sal.fit(X_train_vect_sal, y_train_sal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 361,
     "status": "ok",
     "timestamp": 1714734057252,
     "user": {
      "displayName": "Roha Kabir",
      "userId": "11189408052881390280"
     },
     "user_tz": -300
    },
    "id": "PFcCN5fDEHbR",
    "outputId": "430187d9-b2e3-4119-c476-39a22bfae56b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work-life balance aspect:\n",
      "Accuracy: 0.4009216589861751\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        20\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.00      0.00      0.00        26\n",
      "         4.0       0.26      0.16      0.20        61\n",
      "         5.0       0.45      0.79      0.57        97\n",
      "\n",
      "    accuracy                           0.40       217\n",
      "   macro avg       0.14      0.19      0.15       217\n",
      "weighted avg       0.27      0.40      0.31       217\n",
      "\n",
      "\n",
      "Salary and benefits aspect:\n",
      "Accuracy: 0.3087557603686636\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        17\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.14      0.11      0.12        35\n",
      "         4.0       0.34      0.47      0.40        75\n",
      "         5.0       0.33      0.36      0.34        77\n",
      "\n",
      "    accuracy                           0.31       217\n",
      "   macro avg       0.16      0.19      0.17       217\n",
      "weighted avg       0.26      0.31      0.28       217\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set for each aspect\n",
    "y_pred_wlb = model_wlb.predict(X_test_vect_wlb)\n",
    "y_pred_sal = model_sal.predict(X_test_vect_sal)\n",
    "\n",
    "# Evaluate the performance of each model\n",
    "accuracy_wlb = accuracy_score(y_test_wlb, y_pred_wlb)\n",
    "accuracy_sal = accuracy_score(y_test_sal, y_pred_sal)\n",
    "\n",
    "print(\"Work-life balance aspect:\")\n",
    "print(\"Accuracy:\", accuracy_wlb)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_wlb, y_pred_wlb))\n",
    "\n",
    "print(\"\\nSalary and benefits aspect:\")\n",
    "print(\"Accuracy:\", accuracy_sal)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_sal, y_pred_sal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 536,
     "status": "ok",
     "timestamp": 1714734099428,
     "user": {
      "displayName": "Roha Kabir",
      "userId": "11189408052881390280"
     },
     "user_tz": -300
    },
    "id": "i5-sMOxcFmqd",
    "outputId": "90bb599d-66df-4d7e-99a9-def91d7b9df3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment for Work-Life Balance Aspect: Positive\n",
      "Sentiment for Salary & Benefits Aspect: Positive\n"
     ]
    }
   ],
   "source": [
    "# Example text for testing work-life balance aspect\n",
    "text_wlb = \"The company offers flexible working hours and encourages employees to maintain a healthy work-life balance.\"\n",
    "\n",
    "# Example text for testing salary & benefits aspect\n",
    "text_sal = \"The salary is competitive, and the benefits package includes healthcare, retirement plans, and bonuses.\"\n",
    "\n",
    "# Vectorize the text using TF-IDF\n",
    "text_vect_wlb = vectorizer_wlb.transform([text_wlb])\n",
    "text_vect_sal = vectorizer_sal.transform([text_sal])\n",
    "\n",
    "# Predict sentiment for each aspect\n",
    "sentiment_wlb = model_wlb.predict(text_vect_wlb)\n",
    "sentiment_sal = model_sal.predict(text_vect_sal)\n",
    "# Set threshold for positive and negative sentiments\n",
    "threshold_positive = 4  # Ratings above this threshold are considered positive\n",
    "threshold_negative = 2  # Ratings below this threshold are considered negative\n",
    "\n",
    "# Function to classify sentiment based on threshold\n",
    "def classify_sentiment(rating, threshold_pos, threshold_neg):\n",
    "    if rating > threshold_pos:\n",
    "        return \"Positive\"\n",
    "    elif rating < threshold_neg:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# Predict sentiment for each aspect and classify based on threshold\n",
    "sentiment_wlb = classify_sentiment(sentiment_wlb, threshold_positive, threshold_negative)\n",
    "sentiment_sal = classify_sentiment(sentiment_sal, threshold_positive, threshold_negative)\n",
    "\n",
    "print(\"Sentiment for Work-Life Balance Aspect:\", sentiment_wlb)\n",
    "print(\"Sentiment for Salary & Benefits Aspect:\", sentiment_sal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 407,
     "status": "ok",
     "timestamp": 1714734207210,
     "user": {
      "displayName": "Roha Kabir",
      "userId": "11189408052881390280"
     },
     "user_tz": -300
    },
    "id": "aX1_czEWH2OQ",
    "outputId": "7ff32722-f51a-457f-ba50-dc6318b657cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Define the directory path for the model folder\n",
    "model_dir = 'model'\n",
    "\n",
    "# Create the model directory if it doesn't exist\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# Define the file path for saving the trained models\n",
    "model_wlb_filename = os.path.join(model_dir, 'sentiment_analysis_model_wlb.pkl')\n",
    "model_sal_filename = os.path.join(model_dir, 'sentiment_analysis_model_sal.pkl')\n",
    "\n",
    "# Save the trained models to files\n",
    "joblib.dump(model_wlb, model_wlb_filename)\n",
    "joblib.dump(model_sal, model_sal_filename)\n",
    "\n",
    "print(\"Models saved successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN/oB/5uQnTnm2CEypuB1bY",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
